{
  "id": "snapshot_1758738373457_8yuziaknn",
  "approvalId": "approval_1758738373453_fu80fm9fa",
  "approvalTitle": "AI代码审查API设计文档审批",
  "version": 1,
  "timestamp": "2025-09-24T18:26:13.457Z",
  "trigger": "initial",
  "status": "pending",
  "content": "# Design: AI Code Review API\n\n## 系统架构\n\n### 核心组件设计\n\n```\nAI Code Review API\n├── Controllers\n│   ├── ReviewController (审查管理)\n│   ├── AIModelController (AI模型管理)\n│   ├── ReviewConfigController (审查配置)\n│   └── ReviewHistoryController (审查历史)\n├── Services\n│   ├── ReviewService (审查业务逻辑)\n│   ├── AIModelService (AI模型调用)\n│   ├── CodeAnalysisService (代码分析)\n│   ├── SuggestionService (建议处理)\n│   └── ReviewCacheService (审查缓存)\n├── Providers\n│   ├── OpenAIProvider (OpenAI GPT调用)\n│   ├── AnthropicProvider (Anthropic Claude调用)\n│   └── LocalModelProvider (本地模型支持)\n├── Processors\n│   ├── DiffProcessor (差异解析)\n│   ├── ContextExtractor (上下文提取)\n│   └── SecurityScanner (安全扫描)\n├── Queues\n│   ├── ReviewQueue (审查任务队列)\n│   ├── RetryQueue (重试队列)\n│   └── BatchProcessingQueue (批处理队列)\n├── Guards\n│   ├── ReviewPermissionGuard (审查权限)\n│   └── AIModelQuotaGuard (模型配额限制)\n└── Interceptors\n    ├── ReviewLoggingInterceptor (审查日志)\n    ├── CostTrackingInterceptor (成本跟踪)\n    └── CacheInterceptor (缓存拦截)\n```\n\n## 数据库设计\n\n### 表结构设计\n\n```sql\n-- AI模型配置表\nCREATE TABLE ai_models (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    name VARCHAR(100) NOT NULL,\n    provider ENUM('openai', 'anthropic', 'local', 'other') NOT NULL,\n    model_version VARCHAR(50) NOT NULL,\n    api_endpoint VARCHAR(500),\n    max_tokens INT DEFAULT 4096,\n    temperature DECIMAL(3,2) DEFAULT 0.7,\n    max_retries INT DEFAULT 3,\n    timeout_seconds INT DEFAULT 30,\n    cost_per_1k_tokens DECIMAL(10,4),\n    is_active BOOLEAN DEFAULT TRUE,\n    configuration JSON,\n    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n    \n    INDEX idx_provider (provider),\n    INDEX idx_is_active (is_active),\n    UNIQUE KEY uk_provider_model (provider, model_version)\n);\n\n-- 代码审查表\nCREATE TABLE code_reviews (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    project_id BIGINT NOT NULL,\n    gitlab_project_id BIGINT,\n    merge_request_id BIGINT,\n    merge_request_iid BIGINT,\n    source_branch VARCHAR(200),\n    target_branch VARCHAR(200),\n    commit_sha VARCHAR(40),\n    review_type ENUM('auto', 'manual', 'scheduled') DEFAULT 'auto',\n    status ENUM('pending', 'processing', 'completed', 'failed', 'cancelled') DEFAULT 'pending',\n    ai_model_id BIGINT,\n    configuration JSON,\n    code_diff TEXT,\n    context_files JSON,\n    total_lines_added INT DEFAULT 0,\n    total_lines_removed INT DEFAULT 0,\n    files_changed INT DEFAULT 0,\n    processing_started_at DATETIME,\n    processing_completed_at DATETIME,\n    error_message TEXT,\n    retry_count INT DEFAULT 0,\n    created_by BIGINT,\n    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n    \n    FOREIGN KEY (project_id) REFERENCES projects(id) ON DELETE CASCADE,\n    FOREIGN KEY (ai_model_id) REFERENCES ai_models(id) ON DELETE SET NULL,\n    FOREIGN KEY (created_by) REFERENCES users(id) ON DELETE SET NULL,\n    INDEX idx_project_id (project_id),\n    INDEX idx_merge_request (merge_request_id),\n    INDEX idx_status (status),\n    INDEX idx_created_at (created_at),\n    INDEX idx_processing_time (processing_started_at, processing_completed_at)\n);\n\n-- 审查建议表\nCREATE TABLE review_suggestions (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    review_id BIGINT NOT NULL,\n    file_path VARCHAR(500) NOT NULL,\n    line_number INT,\n    suggestion_type ENUM('bug', 'performance', 'security', 'style', 'best_practice', 'refactor', 'test') NOT NULL,\n    severity ENUM('info', 'low', 'medium', 'high', 'critical') DEFAULT 'medium',\n    title VARCHAR(200) NOT NULL,\n    description TEXT NOT NULL,\n    original_code TEXT,\n    suggested_code TEXT,\n    reasoning TEXT,\n    references JSON,\n    is_resolved BOOLEAN DEFAULT FALSE,\n    resolved_by BIGINT,\n    resolved_at DATETIME,\n    resolution_note TEXT,\n    gitlab_discussion_id BIGINT,\n    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n    \n    FOREIGN KEY (review_id) REFERENCES code_reviews(id) ON DELETE CASCADE,\n    FOREIGN KEY (resolved_by) REFERENCES users(id) ON DELETE SET NULL,\n    INDEX idx_review_id (review_id),\n    INDEX idx_file_path (file_path),\n    INDEX idx_suggestion_type (suggestion_type),\n    INDEX idx_severity (severity),\n    INDEX idx_is_resolved (is_resolved),\n    INDEX idx_created_at (created_at)\n);\n\n-- AI模型使用统计表\nCREATE TABLE ai_model_usage (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    ai_model_id BIGINT NOT NULL,\n    review_id BIGINT NOT NULL,\n    prompt_tokens INT DEFAULT 0,\n    completion_tokens INT DEFAULT 0,\n    total_tokens INT DEFAULT 0,\n    response_time_ms INT,\n    cost_amount DECIMAL(10,4),\n    success BOOLEAN DEFAULT TRUE,\n    error_code VARCHAR(50),\n    error_message TEXT,\n    usage_date DATE,\n    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n    \n    FOREIGN KEY (ai_model_id) REFERENCES ai_models(id) ON DELETE CASCADE,\n    FOREIGN KEY (review_id) REFERENCES code_reviews(id) ON DELETE CASCADE,\n    INDEX idx_ai_model_id (ai_model_id),\n    INDEX idx_review_id (review_id),\n    INDEX idx_usage_date (usage_date),\n    INDEX idx_success (success)\n);\n\n-- 审查配置表\nCREATE TABLE review_configurations (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    project_id BIGINT NOT NULL,\n    name VARCHAR(100) NOT NULL,\n    ai_model_id BIGINT NOT NULL,\n    is_default BOOLEAN DEFAULT FALSE,\n    trigger_conditions JSON,\n    review_scope JSON,\n    prompt_template TEXT,\n    max_files_per_review INT DEFAULT 50,\n    max_lines_per_file INT DEFAULT 1000,\n    enabled_suggestion_types JSON,\n    severity_filter JSON,\n    custom_rules JSON,\n    webhook_config JSON,\n    is_active BOOLEAN DEFAULT TRUE,\n    created_by BIGINT,\n    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n    \n    FOREIGN KEY (project_id) REFERENCES projects(id) ON DELETE CASCADE,\n    FOREIGN KEY (ai_model_id) REFERENCES ai_models(id) ON DELETE RESTRICT,\n    FOREIGN KEY (created_by) REFERENCES users(id) ON DELETE SET NULL,\n    INDEX idx_project_id (project_id),\n    INDEX idx_is_default (is_default),\n    INDEX idx_is_active (is_active),\n    UNIQUE KEY uk_project_default (project_id, is_default)\n);\n\n-- 审查对话表（交互式审查）\nCREATE TABLE review_conversations (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    review_id BIGINT NOT NULL,\n    suggestion_id BIGINT,\n    user_id BIGINT NOT NULL,\n    conversation_data JSON NOT NULL,\n    message_count INT DEFAULT 0,\n    is_active BOOLEAN DEFAULT TRUE,\n    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n    \n    FOREIGN KEY (review_id) REFERENCES code_reviews(id) ON DELETE CASCADE,\n    FOREIGN KEY (suggestion_id) REFERENCES review_suggestions(id) ON DELETE SET NULL,\n    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,\n    INDEX idx_review_id (review_id),\n    INDEX idx_user_id (user_id),\n    INDEX idx_is_active (is_active)\n);\n```\n\n## API接口设计\n\n### Controller设计\n\n#### ReviewController\n\n```typescript\n@Controller('api/reviews')\n@UseGuards(JwtAuthGuard)\n@UseInterceptors(ReviewLoggingInterceptor)\nexport class ReviewController {\n  constructor(\n    private readonly reviewService: ReviewService,\n    private readonly suggestionService: SuggestionService,\n  ) {}\n\n  @Post()\n  @UseGuards(ReviewPermissionGuard)\n  async createReview(@Body() createDto: CreateReviewDto) {\n    return this.reviewService.createReview(createDto);\n  }\n\n  @Post(':id/trigger')\n  async triggerReview(@Param('id') reviewId: string) {\n    return this.reviewService.triggerReview(+reviewId);\n  }\n\n  @Get(':id')\n  async getReview(@Param('id') reviewId: string) {\n    return this.reviewService.getReviewDetails(+reviewId);\n  }\n\n  @Get(':id/suggestions')\n  async getSuggestions(\n    @Param('id') reviewId: string,\n    @Query() query: SuggestionQueryDto,\n  ) {\n    return this.suggestionService.getSuggestionsByReview(+reviewId, query);\n  }\n\n  @Put('suggestions/:suggestionId/resolve')\n  async resolveSuggestion(\n    @Param('suggestionId') suggestionId: string,\n    @Body() resolveDto: ResolveSuggestionDto,\n  ) {\n    return this.suggestionService.resolveSuggestion(+suggestionId, resolveDto);\n  }\n\n  @Post(':id/chat')\n  async startConversation(\n    @Param('id') reviewId: string,\n    @Body() chatDto: ReviewChatDto,\n  ) {\n    return this.reviewService.startConversation(+reviewId, chatDto);\n  }\n\n  @Get('project/:projectId')\n  async getProjectReviews(\n    @Param('projectId') projectId: string,\n    @Query() query: ReviewListQueryDto,\n  ) {\n    return this.reviewService.getProjectReviews(+projectId, query);\n  }\n}\n```\n\n#### AIModelController\n\n```typescript\n@Controller('api/ai-models')\n@UseGuards(JwtAuthGuard, AdminGuard)\nexport class AIModelController {\n  constructor(private readonly aiModelService: AIModelService) {}\n\n  @Get()\n  async listModels(@Query() query: ModelListQueryDto) {\n    return this.aiModelService.listModels(query);\n  }\n\n  @Post()\n  async createModel(@Body() createDto: CreateModelDto) {\n    return this.aiModelService.createModel(createDto);\n  }\n\n  @Put(':id')\n  async updateModel(\n    @Param('id') modelId: string,\n    @Body() updateDto: UpdateModelDto,\n  ) {\n    return this.aiModelService.updateModel(+modelId, updateDto);\n  }\n\n  @Post(':id/test')\n  async testModel(@Param('id') modelId: string) {\n    return this.aiModelService.testModelConnection(+modelId);\n  }\n\n  @Get(':id/usage')\n  async getModelUsage(\n    @Param('id') modelId: string,\n    @Query() query: UsageQueryDto,\n  ) {\n    return this.aiModelService.getUsageStatistics(+modelId, query);\n  }\n}\n```\n\n### Service设计\n\n#### ReviewService\n\n```typescript\n@Injectable()\nexport class ReviewService {\n  constructor(\n    @InjectRepository(CodeReview)\n    private readonly reviewRepo: Repository<CodeReview>,\n    private readonly aiModelService: AIModelService,\n    private readonly codeAnalysisService: CodeAnalysisService,\n    private readonly suggestionService: SuggestionService,\n    private readonly reviewCacheService: ReviewCacheService,\n    @InjectQueue('review') private readonly reviewQueue: Queue,\n  ) {}\n\n  async createReview(createDto: CreateReviewDto) {\n    // 创建审查记录\n    const review = await this.reviewRepo.save({\n      projectId: createDto.projectId,\n      gitlabProjectId: createDto.gitlabProjectId,\n      mergeRequestId: createDto.mergeRequestId,\n      mergeRequestIid: createDto.mergeRequestIid,\n      sourceBranch: createDto.sourceBranch,\n      targetBranch: createDto.targetBranch,\n      commitSha: createDto.commitSha,\n      reviewType: createDto.reviewType || 'manual',\n      aiModelId: createDto.aiModelId,\n      configuration: createDto.configuration,\n      codeDiff: createDto.codeDiff,\n      createdBy: createDto.userId,\n    });\n\n    // 异步处理审查\n    await this.reviewQueue.add('process-review', {\n      reviewId: review.id,\n      priority: createDto.priority || 'normal',\n    }, {\n      attempts: 3,\n      backoff: {\n        type: 'exponential',\n        delay: 2000,\n      },\n      removeOnComplete: 100,\n      removeOnFail: 50,\n    });\n\n    return this.formatReviewResponse(review);\n  }\n\n  @Process('process-review')\n  async processReview(job: Job) {\n    const { reviewId } = job.data;\n    const review = await this.reviewRepo.findOne({ where: { id: reviewId } });\n    \n    if (!review) {\n      throw new Error(`Review ${reviewId} not found`);\n    }\n\n    try {\n      // 更新状态为处理中\n      await this.reviewRepo.update(reviewId, {\n        status: 'processing',\n        processingStartedAt: new Date(),\n      });\n\n      // 代码分析\n      const analysisResult = await this.codeAnalysisService.analyzeDiff(\n        review.codeDiff,\n        review.configuration,\n      );\n\n      // AI模型调用\n      const suggestions = await this.aiModelService.generateSuggestions(\n        review.aiModelId,\n        analysisResult,\n        review.configuration,\n      );\n\n      // 保存建议\n      await this.suggestionService.saveSuggestions(reviewId, suggestions);\n\n      // 更新完成状态\n      await this.reviewRepo.update(reviewId, {\n        status: 'completed',\n        processingCompletedAt: new Date(),\n      });\n\n      // 缓存结果\n      await this.reviewCacheService.cacheReviewResult(reviewId, suggestions);\n\n    } catch (error) {\n      await this.reviewRepo.update(reviewId, {\n        status: 'failed',\n        errorMessage: error.message,\n        retryCount: review.retryCount + 1,\n      });\n\n      // 如果重试次数未超限，重新加入队列\n      if (review.retryCount < 2) {\n        await this.reviewQueue.add('process-review', {\n          reviewId,\n          priority: 'retry',\n        }, {\n          delay: Math.pow(2, review.retryCount) * 5000, // 指数退避\n        });\n      }\n\n      throw error;\n    }\n  }\n\n  async startConversation(reviewId: number, chatDto: ReviewChatDto) {\n    const review = await this.reviewRepo.findOne({ where: { id: reviewId } });\n    if (!review) {\n      throw new NotFoundException('Review not found');\n    }\n\n    // 获取对话上下文\n    const context = await this.buildConversationContext(reviewId, chatDto.suggestionId);\n    \n    // 调用AI模型进行对话\n    const response = await this.aiModelService.chat(\n      review.aiModelId,\n      chatDto.message,\n      context,\n    );\n\n    // 保存对话记录\n    return this.saveConversationMessage(reviewId, chatDto, response);\n  }\n}\n```\n\n#### AIModelService\n\n```typescript\n@Injectable()\nexport class AIModelService {\n  constructor(\n    @InjectRepository(AiModel)\n    private readonly modelRepo: Repository<AiModel>,\n    @InjectRepository(AiModelUsage)\n    private readonly usageRepo: Repository<AiModelUsage>,\n    private readonly openaiProvider: OpenAIProvider,\n    private readonly anthropicProvider: AnthropicProvider,\n    private readonly localProvider: LocalModelProvider,\n  ) {}\n\n  async generateSuggestions(\n    modelId: number,\n    analysisResult: CodeAnalysisResult,\n    configuration: any,\n  ): Promise<ReviewSuggestion[]> {\n    const model = await this.modelRepo.findOne({ where: { id: modelId } });\n    if (!model || !model.isActive) {\n      throw new NotFoundException('AI model not found or inactive');\n    }\n\n    const provider = this.getProvider(model.provider);\n    const startTime = Date.now();\n\n    try {\n      // 构建提示词\n      const prompt = this.buildPrompt(analysisResult, configuration);\n      \n      // 调用AI模型\n      const response = await provider.generateSuggestions(model, prompt);\n      \n      // 记录使用统计\n      await this.recordUsage(modelId, response, Date.now() - startTime);\n      \n      // 解析响应为建议格式\n      return this.parseSuggestions(response, analysisResult);\n\n    } catch (error) {\n      await this.recordUsage(modelId, null, Date.now() - startTime, error);\n      throw error;\n    }\n  }\n\n  async chat(\n    modelId: number,\n    message: string,\n    context: ConversationContext,\n  ): Promise<string> {\n    const model = await this.modelRepo.findOne({ where: { id: modelId } });\n    if (!model || !model.isActive) {\n      throw new NotFoundException('AI model not found or inactive');\n    }\n\n    const provider = this.getProvider(model.provider);\n    const startTime = Date.now();\n\n    try {\n      const response = await provider.chat(model, message, context);\n      await this.recordUsage(modelId, response, Date.now() - startTime);\n      return response.content;\n    } catch (error) {\n      await this.recordUsage(modelId, null, Date.now() - startTime, error);\n      throw error;\n    }\n  }\n\n  private getProvider(providerType: string) {\n    switch (providerType) {\n      case 'openai':\n        return this.openaiProvider;\n      case 'anthropic':\n        return this.anthropicProvider;\n      case 'local':\n        return this.localProvider;\n      default:\n        throw new BadRequestException(`Unsupported provider: ${providerType}`);\n    }\n  }\n\n  private buildPrompt(analysisResult: CodeAnalysisResult, configuration: any): string {\n    const template = configuration.promptTemplate || this.getDefaultPromptTemplate();\n    \n    return template\n      .replace('{DIFF}', analysisResult.diff)\n      .replace('{CONTEXT}', JSON.stringify(analysisResult.context))\n      .replace('{LANGUAGE}', analysisResult.primaryLanguage)\n      .replace('{RULES}', JSON.stringify(configuration.customRules || {}));\n  }\n\n  private async recordUsage(\n    modelId: number,\n    response: any,\n    responseTime: number,\n    error?: Error,\n  ): Promise<void> {\n    await this.usageRepo.save({\n      aiModelId: modelId,\n      promptTokens: response?.usage?.prompt_tokens || 0,\n      completionTokens: response?.usage?.completion_tokens || 0,\n      totalTokens: response?.usage?.total_tokens || 0,\n      responseTimeMs: responseTime,\n      costAmount: this.calculateCost(modelId, response?.usage),\n      success: !error,\n      errorCode: error?.name,\n      errorMessage: error?.message,\n      usageDate: new Date().toISOString().split('T')[0],\n    });\n  }\n}\n```\n\n### Provider实现\n\n#### OpenAIProvider\n\n```typescript\n@Injectable()\nexport class OpenAIProvider {\n  private openai: OpenAI;\n\n  constructor() {\n    this.openai = new OpenAI({\n      apiKey: process.env.OPENAI_API_KEY,\n      baseURL: process.env.OPENAI_BASE_URL,\n    });\n  }\n\n  async generateSuggestions(model: AiModel, prompt: string) {\n    const response = await this.openai.chat.completions.create({\n      model: model.modelVersion,\n      messages: [\n        {\n          role: 'system',\n          content: 'You are an expert code reviewer. Analyze the provided code and give specific, actionable feedback.',\n        },\n        {\n          role: 'user',\n          content: prompt,\n        },\n      ],\n      max_tokens: model.maxTokens,\n      temperature: model.temperature,\n      response_format: { type: 'json_object' },\n    });\n\n    return response;\n  }\n\n  async chat(model: AiModel, message: string, context: ConversationContext) {\n    const messages = this.buildChatMessages(context, message);\n    \n    const response = await this.openai.chat.completions.create({\n      model: model.modelVersion,\n      messages,\n      max_tokens: Math.min(model.maxTokens, 2000), // 对话限制更少token\n      temperature: model.temperature,\n    });\n\n    return response.choices[0];\n  }\n\n  private buildChatMessages(context: ConversationContext, message: string) {\n    const messages = [\n      {\n        role: 'system' as const,\n        content: `You are helping with code review. Context: ${context.reviewSummary}`,\n      },\n    ];\n\n    // 添加历史对话\n    context.previousMessages.forEach(msg => {\n      messages.push({\n        role: msg.role as 'user' | 'assistant',\n        content: msg.content,\n      });\n    });\n\n    // 添加当前消息\n    messages.push({\n      role: 'user' as const,\n      content: message,\n    });\n\n    return messages;\n  }\n}\n```\n\n#### AnthropicProvider\n\n```typescript\n@Injectable()\nexport class AnthropicProvider {\n  private anthropic: Anthropic;\n\n  constructor() {\n    this.anthropic = new Anthropic({\n      apiKey: process.env.ANTHROPIC_API_KEY,\n    });\n  }\n\n  async generateSuggestions(model: AiModel, prompt: string) {\n    const response = await this.anthropic.messages.create({\n      model: model.modelVersion,\n      max_tokens: model.maxTokens,\n      temperature: model.temperature,\n      system: 'You are an expert code reviewer. Return your analysis in valid JSON format.',\n      messages: [\n        {\n          role: 'user',\n          content: prompt,\n        },\n      ],\n    });\n\n    return {\n      choices: [{\n        message: {\n          content: response.content[0].type === 'text' ? response.content[0].text : '',\n        },\n      }],\n      usage: {\n        prompt_tokens: response.usage.input_tokens,\n        completion_tokens: response.usage.output_tokens,\n        total_tokens: response.usage.input_tokens + response.usage.output_tokens,\n      },\n    };\n  }\n\n  async chat(model: AiModel, message: string, context: ConversationContext) {\n    const messages = this.buildChatMessages(context, message);\n    \n    const response = await this.anthropic.messages.create({\n      model: model.modelVersion,\n      max_tokens: Math.min(model.maxTokens, 2000),\n      temperature: model.temperature,\n      system: `You are helping with code review. Context: ${context.reviewSummary}`,\n      messages,\n    });\n\n    return {\n      message: {\n        content: response.content[0].type === 'text' ? response.content[0].text : '',\n      },\n      usage: {\n        prompt_tokens: response.usage.input_tokens,\n        completion_tokens: response.usage.output_tokens,\n        total_tokens: response.usage.input_tokens + response.usage.output_tokens,\n      },\n    };\n  }\n}\n```\n\n## 代码分析引擎\n\n### DiffProcessor\n\n```typescript\n@Injectable()\nexport class DiffProcessor {\n  parseDiff(diffText: string): ParsedDiff {\n    const files = [];\n    const lines = diffText.split('\\n');\n    let currentFile = null;\n    let currentHunk = null;\n\n    for (const line of lines) {\n      if (line.startsWith('diff --git')) {\n        if (currentFile) {\n          files.push(currentFile);\n        }\n        currentFile = {\n          path: this.extractFilePath(line),\n          hunks: [],\n          additions: 0,\n          deletions: 0,\n        };\n      } else if (line.startsWith('@@') && currentFile) {\n        if (currentHunk) {\n          currentFile.hunks.push(currentHunk);\n        }\n        currentHunk = {\n          oldStart: this.extractOldStart(line),\n          newStart: this.extractNewStart(line),\n          context: this.extractContext(line),\n          changes: [],\n        };\n      } else if (currentHunk && (line.startsWith('+') || line.startsWith('-') || line.startsWith(' '))) {\n        const change = {\n          type: line[0] as '+' | '-' | ' ',\n          content: line.slice(1),\n          lineNumber: this.calculateLineNumber(currentHunk, line[0]),\n        };\n        currentHunk.changes.push(change);\n        \n        if (line.startsWith('+')) {\n          currentFile.additions++;\n        } else if (line.startsWith('-')) {\n          currentFile.deletions++;\n        }\n      }\n    }\n\n    if (currentHunk && currentFile) {\n      currentFile.hunks.push(currentHunk);\n    }\n    if (currentFile) {\n      files.push(currentFile);\n    }\n\n    return {\n      files,\n      totalAdditions: files.reduce((sum, f) => sum + f.additions, 0),\n      totalDeletions: files.reduce((sum, f) => sum + f.deletions, 0),\n      totalFiles: files.length,\n    };\n  }\n\n  extractSecurityIssues(diff: ParsedDiff): SecurityIssue[] {\n    const issues = [];\n    \n    for (const file of diff.files) {\n      for (const hunk of file.hunks) {\n        for (const change of hunk.changes) {\n          if (change.type === '+') {\n            // 检查常见安全问题\n            const content = change.content.toLowerCase();\n            \n            if (content.includes('password') && content.includes('=')) {\n              issues.push({\n                type: 'hardcoded_credential',\n                file: file.path,\n                line: change.lineNumber,\n                severity: 'high',\n                message: 'Potential hardcoded password detected',\n              });\n            }\n            \n            if (content.includes('sql') && (content.includes('+') || content.includes('concat'))) {\n              issues.push({\n                type: 'sql_injection',\n                file: file.path,\n                line: change.lineNumber,\n                severity: 'high',\n                message: 'Potential SQL injection vulnerability',\n              });\n            }\n          }\n        }\n      }\n    }\n    \n    return issues;\n  }\n}\n```\n\n### ContextExtractor\n\n```typescript\n@Injectable()\nexport class ContextExtractor {\n  async extractContext(\n    diff: ParsedDiff,\n    gitlabProjectId: number,\n    commitSha: string,\n  ): Promise<CodeContext> {\n    const context = {\n      mainLanguage: this.detectMainLanguage(diff),\n      fileContexts: [],\n      dependencies: [],\n      projectStructure: {},\n    };\n\n    for (const file of diff.files) {\n      const fileContext = await this.extractFileContext(\n        file,\n        gitlabProjectId,\n        commitSha,\n      );\n      context.fileContexts.push(fileContext);\n    }\n\n    // 分析依赖关系\n    context.dependencies = await this.analyzeDependencies(diff);\n\n    return context;\n  }\n\n  private detectMainLanguage(diff: ParsedDiff): string {\n    const extensions = {};\n    \n    for (const file of diff.files) {\n      const ext = path.extname(file.path).toLowerCase();\n      extensions[ext] = (extensions[ext] || 0) + 1;\n    }\n\n    const sortedExts = Object.entries(extensions)\n      .sort(([, a], [, b]) => (b as number) - (a as number));\n\n    const languageMap = {\n      '.js': 'javascript',\n      '.ts': 'typescript',\n      '.py': 'python',\n      '.java': 'java',\n      '.go': 'go',\n      '.rs': 'rust',\n      '.cpp': 'cpp',\n      '.c': 'c',\n    };\n\n    return languageMap[sortedExts[0]?.[0]] || 'unknown';\n  }\n\n  private async extractFileContext(\n    file: ParsedFile,\n    gitlabProjectId: number,\n    commitSha: string,\n  ): Promise<FileContext> {\n    // 获取完整文件内容用于上下文分析\n    const fullContent = await this.getFileContent(\n      gitlabProjectId,\n      file.path,\n      commitSha,\n    );\n\n    return {\n      path: file.path,\n      language: this.detectFileLanguage(file.path),\n      imports: this.extractImports(fullContent),\n      functions: this.extractFunctions(fullContent),\n      classes: this.extractClasses(fullContent),\n      complexity: this.calculateComplexity(fullContent),\n    };\n  }\n}\n```\n\n## 缓存与性能优化\n\n### ReviewCacheService\n\n```typescript\n@Injectable()\nexport class ReviewCacheService {\n  constructor(private readonly redisService: RedisService) {}\n\n  async cacheReviewResult(reviewId: number, suggestions: ReviewSuggestion[]): Promise<void> {\n    const key = `review:${reviewId}`;\n    const data = {\n      suggestions,\n      cachedAt: new Date().toISOString(),\n    };\n    \n    // 缓存24小时\n    await this.redisService.setex(key, 86400, JSON.stringify(data));\n  }\n\n  async getCachedReview(reviewId: number): Promise<ReviewSuggestion[] | null> {\n    const key = `review:${reviewId}`;\n    const cached = await this.redisService.get(key);\n    \n    if (cached) {\n      const data = JSON.parse(cached);\n      return data.suggestions;\n    }\n    \n    return null;\n  }\n\n  async cacheSimilarReview(diffHash: string, suggestions: ReviewSuggestion[]): Promise<void> {\n    const key = `similar:${diffHash}`;\n    await this.redisService.setex(key, 3600, JSON.stringify(suggestions)); // 1小时\n  }\n\n  async findSimilarReview(diffHash: string): Promise<ReviewSuggestion[] | null> {\n    const key = `similar:${diffHash}`;\n    const cached = await this.redisService.get(key);\n    \n    return cached ? JSON.parse(cached) : null;\n  }\n}\n```\n\n## 成本控制\n\n### CostTrackingInterceptor\n\n```typescript\n@Injectable()\nexport class CostTrackingInterceptor implements NestInterceptor {\n  constructor(\n    private readonly usageRepo: Repository<AiModelUsage>,\n    private readonly configService: ConfigService,\n  ) {}\n\n  async intercept(context: ExecutionContext, next: CallHandler): Promise<Observable<any>> {\n    const request = context.switchToHttp().getRequest();\n    const userId = request.user?.id;\n    const projectId = request.body?.projectId;\n\n    // 检查用户/项目配额\n    const monthlyUsage = await this.getMonthlyUsage(userId, projectId);\n    const monthlyLimit = this.configService.get('AI_MONTHLY_LIMIT', 1000);\n\n    if (monthlyUsage >= monthlyLimit) {\n      throw new HttpException('Monthly AI usage limit exceeded', HttpStatus.PAYMENT_REQUIRED);\n    }\n\n    // 检查日使用量\n    const dailyUsage = await this.getDailyUsage(userId, projectId);\n    const dailyLimit = this.configService.get('AI_DAILY_LIMIT', 100);\n\n    if (dailyUsage >= dailyLimit) {\n      throw new HttpException('Daily AI usage limit exceeded', HttpStatus.TOO_MANY_REQUESTS);\n    }\n\n    return next.handle();\n  }\n\n  private async getMonthlyUsage(userId: number, projectId?: number): Promise<number> {\n    const startOfMonth = new Date();\n    startOfMonth.setDate(1);\n    startOfMonth.setHours(0, 0, 0, 0);\n\n    const query = this.usageRepo\n      .createQueryBuilder('usage')\n      .innerJoin('usage.review', 'review')\n      .where('review.created_by = :userId', { userId })\n      .andWhere('usage.created_at >= :startOfMonth', { startOfMonth });\n\n    if (projectId) {\n      query.andWhere('review.project_id = :projectId', { projectId });\n    }\n\n    const result = await query\n      .select('SUM(usage.total_tokens)', 'totalTokens')\n      .getRawOne();\n\n    return parseInt(result.totalTokens || '0');\n  }\n}\n```\n\n## 监控与日志\n\n### ReviewLoggingInterceptor\n\n```typescript\n@Injectable()\nexport class ReviewLoggingInterceptor implements NestInterceptor {\n  private readonly logger = new Logger(ReviewLoggingInterceptor.name);\n\n  intercept(context: ExecutionContext, next: CallHandler): Observable<any> {\n    const request = context.switchToHttp().getRequest();\n    const { method, url, user, body } = request;\n    const startTime = Date.now();\n\n    this.logger.log(`[${method}] ${url} - User: ${user?.id} - Started`);\n\n    return next.handle().pipe(\n      tap({\n        next: (data) => {\n          const duration = Date.now() - startTime;\n          this.logger.log(\n            `[${method}] ${url} - User: ${user?.id} - Completed in ${duration}ms`,\n          );\n          \n          // 记录关键操作\n          if (url.includes('/reviews') && method === 'POST') {\n            this.logger.log(\n              `Review created: ${JSON.stringify({ \n                projectId: body.projectId, \n                mergeRequestId: body.mergeRequestId,\n                duration \n              })}`,\n            );\n          }\n        },\n        error: (error) => {\n          const duration = Date.now() - startTime;\n          this.logger.error(\n            `[${method}] ${url} - User: ${user?.id} - Failed in ${duration}ms: ${error.message}`,\n            error.stack,\n          );\n        },\n      }),\n    );\n  }\n}\n```\n\n## 配置管理\n\n### AI模型配置\n\n```typescript\nexport interface AIModelConfig {\n  models: {\n    openai: {\n      apiKey: string;\n      baseUrl?: string;\n      models: string[];\n      defaultModel: string;\n    };\n    anthropic: {\n      apiKey: string;\n      models: string[];\n      defaultModel: string;\n    };\n  };\n  limits: {\n    maxTokensPerRequest: number;\n    maxRequestsPerMinute: number;\n    maxCostPerMonth: number;\n  };\n  prompts: {\n    defaultTemplate: string;\n    securityFocused: string;\n    performanceFocused: string;\n  };\n}\n\n@Injectable()\nexport class AIConfigService {\n  private readonly config: AIModelConfig;\n\n  constructor(private readonly configService: ConfigService) {\n    this.config = {\n      models: {\n        openai: {\n          apiKey: this.configService.get('OPENAI_API_KEY'),\n          baseUrl: this.configService.get('OPENAI_BASE_URL'),\n          models: ['gpt-4', 'gpt-4-turbo', 'gpt-3.5-turbo'],\n          defaultModel: 'gpt-4',\n        },\n        anthropic: {\n          apiKey: this.configService.get('ANTHROPIC_API_KEY'),\n          models: ['claude-3-opus', 'claude-3-sonnet', 'claude-3-haiku'],\n          defaultModel: 'claude-3-sonnet',\n        },\n      },\n      limits: {\n        maxTokensPerRequest: +this.configService.get('AI_MAX_TOKENS', '4000'),\n        maxRequestsPerMinute: +this.configService.get('AI_MAX_REQUESTS_PER_MINUTE', '10'),\n        maxCostPerMonth: +this.configService.get('AI_MAX_COST_PER_MONTH', '100'),\n      },\n      prompts: {\n        defaultTemplate: this.getDefaultPromptTemplate(),\n        securityFocused: this.getSecurityPromptTemplate(),\n        performanceFocused: this.getPerformancePromptTemplate(),\n      },\n    };\n  }\n}\n```\n\n## 测试策略\n\n### 单元测试重点\n\n- ReviewService: 审查创建、状态管理、错误处理\n- AIModelService: 模型调用、响应解析、成本计算\n- DiffProcessor: 差异解析、安全检测、语言识别\n- Providers: OpenAI/Anthropic API调用、错误处理\n- CacheService: 缓存策略、相似度检测\n- CostTracking: 配额检查、使用统计\n\n### 集成测试\n\n- 完整审查流程测试\n- AI模型集成测试\n- WebHook触发测试\n- 数据库事务测试\n- 队列处理测试\n\n### E2E测试\n\n- GitLab MR触发完整审查流程\n- 多模型对比测试\n- 成本控制验证\n- 性能压力测试\n\n## 部署配置\n\n1. **AI模型API密钥**: 配置OpenAI和Anthropic API密钥\n2. **队列服务**: 配置BullMQ用于异步处理\n3. **缓存服务**: 配置Redis用于结果缓存\n4. **监控配置**: 设置日志收集和性能监控\n5. **成本监控**: 配置使用量和成本预警\n6. **安全配置**: 确保API密钥安全存储\n7. **模型配置**: 根据需求配置默认AI模型",
  "fileStats": {
    "size": 33335,
    "lines": 1150,
    "lastModified": "2025-09-24T18:13:20.859Z"
  },
  "comments": []
}